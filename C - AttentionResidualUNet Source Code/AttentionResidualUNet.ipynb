{"cells":[{"cell_type":"markdown","source":["# Go through the each cell.. used Chatgpt to understood each cell.."],"metadata":{"id":"FXPTjB9YLlZS"}},{"cell_type":"markdown","metadata":{"id":"bQHLCLsXIC5T"},"source":["# Mount Drive"]},{"cell_type":"code","execution_count":14,"metadata":{"collapsed":true,"id":"ZLXUjg0IIFKz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762436736050,"user_tz":-360,"elapsed":3441,"user":{"displayName":"Mobashara Mobashara","userId":"14068009748502855723"}},"outputId":"c97667ea-6128-4c33-943b-c4c8eb631c7a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# @title\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"hliqQzI_wvBO"},"source":["#                                     1. Imports and Utilities"]},{"cell_type":"code","execution_count":15,"metadata":{"collapsed":true,"id":"AeGsnVWdGyzD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762436776264,"user_tz":-360,"elapsed":37618,"user":{"displayName":"Mobashara Mobashara","userId":"14068009748502855723"}},"outputId":"70bc5d58-180c-4b07-c53e-fc77beb3ac09"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: kornia in /usr/local/lib/python3.12/dist-packages (0.8.1)\n","Requirement already satisfied: torchmetrics in /usr/local/lib/python3.12/dist-packages (1.8.2)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (0.25.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n","Requirement already satisfied: kornia_rs>=0.1.9 in /usr/local/lib/python3.12/dist-packages (from kornia) (0.1.9)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kornia) (25.0)\n","Requirement already satisfied: torch>=1.9.1 in /usr/local/lib/python3.12/dist-packages (from kornia) (2.8.0+cu126)\n","Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n","Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (0.15.2)\n","Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (1.16.3)\n","Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (3.5)\n","Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (11.3.0)\n","Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2.37.0)\n","Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2025.10.16)\n","Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (0.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (3.20.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (1.13.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (3.4.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.9.1->kornia) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.9.1->kornia) (3.0.3)\n","Requirement already satisfied: kornia in /usr/local/lib/python3.12/dist-packages (0.8.1)\n","Requirement already satisfied: torchmetrics in /usr/local/lib/python3.12/dist-packages (1.8.2)\n","Requirement already satisfied: kornia_rs>=0.1.9 in /usr/local/lib/python3.12/dist-packages (from kornia) (0.1.9)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kornia) (25.0)\n","Requirement already satisfied: torch>=1.9.1 in /usr/local/lib/python3.12/dist-packages (from kornia) (2.8.0+cu126)\n","Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n","Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (0.15.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (3.20.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (3.4.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.9.1->kornia) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.9.1->kornia) (3.0.3)\n","Requirement already satisfied: torchmetrics in /usr/local/lib/python3.12/dist-packages (1.8.2)\n","Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n","Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (25.0)\n","Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.8.0+cu126)\n","Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (0.15.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.20.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.3)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (0.25.2)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n","Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2.0.2)\n","Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (1.16.3)\n","Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (3.5)\n","Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (11.3.0)\n","Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2.37.0)\n","Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2025.10.16)\n","Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (25.0)\n","Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (0.4)\n","Requirement already satisfied: torch==2.8.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.8.0+cu126)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (1.13.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (3.4.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch==2.8.0->torchvision) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.8.0->torchvision) (3.0.3)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (0.25.2)\n","Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2.0.2)\n","Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (1.16.3)\n","Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (3.5)\n","Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (11.3.0)\n","Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2.37.0)\n","Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2025.10.16)\n","Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (25.0)\n","Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (0.4)\n","Requirement already satisfied: lpips in /usr/local/lib/python3.12/dist-packages (0.1.4)\n","Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from lpips) (2.8.0+cu126)\n","Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from lpips) (0.23.0+cu126)\n","Requirement already satisfied: numpy>=1.14.3 in /usr/local/lib/python3.12/dist-packages (from lpips) (2.0.2)\n","Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from lpips) (1.16.3)\n","Requirement already satisfied: tqdm>=4.28.1 in /usr/local/lib/python3.12/dist-packages (from lpips) (4.67.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (3.4.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision>=0.2.1->lpips) (11.3.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=0.4.0->lpips) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=0.4.0->lpips) (3.0.3)\n","Requirement already satisfied: torchviz in /usr/local/lib/python3.12/dist-packages (0.0.3)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (0.21)\n","Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from torchviz) (2.8.0+cu126)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (3.4.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->torchviz) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->torchviz) (3.0.3)\n","Requirement already satisfied: kornia in /usr/local/lib/python3.12/dist-packages (0.8.1)\n","Requirement already satisfied: kornia_rs>=0.1.9 in /usr/local/lib/python3.12/dist-packages (from kornia) (0.1.9)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kornia) (25.0)\n","Requirement already satisfied: torch>=1.9.1 in /usr/local/lib/python3.12/dist-packages (from kornia) (2.8.0+cu126)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia) (3.4.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.9.1->kornia) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.9.1->kornia) (3.0.3)\n"]}],"source":["# @title\n","!pip install kornia torchmetrics scikit-image tqdm\n","!pip install kornia torchmetrics\n","!pip install torchmetrics\n","!pip install scikit-image torchvision\n","!pip install scikit-image\n","!pip install lpips\n","!pip install torchviz graphviz\n","!pip install kornia"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"neNeqPPawpr1","executionInfo":{"status":"ok","timestamp":1762436848748,"user_tz":-360,"elapsed":22,"user":{"displayName":"Mobashara Mobashara","userId":"14068009748502855723"}}},"outputs":[],"source":["# @title\n","# =========================================================\n","# Imports for Deep Learning and Computer Vision\n","# =========================================================\n","import os\n","import csv\n","import json\n","import numpy as np\n","import pandas as pd\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","\n","import torchvision.transforms as transforms\n","from torchvision.utils import save_image\n","import torchvision.models as models\n","from torchvision.models import vgg16 # Specifically imported for potential feature extraction\n","\n","import kornia\n","from kornia.color import rgb_to_hsv\n","\n","# Metrics\n","from torchmetrics.image import StructuralSimilarityIndexMeasure, PeakSignalNoiseRatio\n","from skimage.metrics import structural_similarity as ssim_sk, peak_signal_noise_ratio as psnr_sk\n","\n","from tqdm import tqdm # For progress bars"]},{"cell_type":"markdown","metadata":{"id":"Tb19DYJ3w1su"},"source":["# 2. Dataset: Paired Distorted / Clean Images"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"PWdDkpbsw4QZ","executionInfo":{"status":"ok","timestamp":1762436854411,"user_tz":-360,"elapsed":38,"user":{"displayName":"Mobashara Mobashara","userId":"14068009748502855723"}}},"outputs":[],"source":["# @title\n","# =========================================================\n","# 2. Dataset: ImagePairDataset (Fixed Joint Transform Seed)\n","# =========================================================\n","class ImagePairDataset(Dataset):\n","    \"\"\"\n","    Paired dataset for distorted -> clean image reconstruction.\n","    Returns: (dist_tensor, clean_tensor, path_str)\n","    \"\"\"\n","    # noise image subtitle:\n","    # Dataset / Noise Folder / open a image / click three dot\n","    #  #  #  #\n","    def __init__(self, distorted_dir, clean_dir, transform=None,\n","                 dist_suffix='_noise4_multiply_strong', clean_suffix='_original'): # e.g _gaussian\n","        self.distorted_dir = distorted_dir\n","        self.clean_dir = clean_dir\n","        self.transform = transform\n","        self.dist_suffix = dist_suffix\n","        self.clean_suffix = clean_suffix\n","\n","        distorted_filenames = sorted([\n","            f for f in os.listdir(distorted_dir)\n","            if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n","        ])\n","\n","        print(f\"ðŸ“ Found {len(distorted_filenames)} distorted images in {distorted_dir}\")\n","        self.data_pairs = []\n","        for dist_file in distorted_filenames:\n","            clean_file = dist_file.replace(dist_suffix, clean_suffix)\n","            dist_path = os.path.join(distorted_dir, dist_file)\n","            clean_path = os.path.join(clean_dir, clean_file)\n","            if os.path.exists(clean_path):\n","                self.data_pairs.append((dist_path, clean_path))\n","            else:\n","                print(f\"   âš ï¸ Clean not found for {dist_file}\")\n","\n","        if not self.data_pairs:\n","            raise FileNotFoundError(\"No valid image pairs found!\")\n","\n","        print(f\"âœ… Dataset ready with {len(self.data_pairs)} image pairs\")\n","\n","    def __len__(self):\n","        return len(self.data_pairs)\n","\n","    def __getitem__(self, idx):\n","        dist_path, clean_path = self.data_pairs[idx]\n","        dist_img = Image.open(dist_path).convert(\"RGB\")\n","        clean_img = Image.open(clean_path).convert(\"RGB\")\n","\n","        # Apply same random seed for paired augmentations to keep alignment\n","        seed = np.random.randint(2147483647)\n","        torch.manual_seed(seed)\n","        if self.transform:\n","            dist_tensor = self.transform(dist_img)\n","        else:\n","            dist_tensor = transforms.ToTensor()(dist_img)\n","\n","        torch.manual_seed(seed)\n","        if self.transform:\n","            clean_tensor = self.transform(clean_img)\n","        else:\n","            clean_tensor = transforms.ToTensor()(clean_img)\n","\n","        return dist_tensor, clean_tensor, dist_path"]},{"cell_type":"markdown","metadata":{"id":"M938r7GGw7in"},"source":["# 3. Model: Attention Residual U-Net (ARU-Net)"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"GninAsmMw860","executionInfo":{"status":"ok","timestamp":1762436860319,"user_tz":-360,"elapsed":32,"user":{"displayName":"Mobashara Mobashara","userId":"14068009748502855723"}}},"outputs":[],"source":["# @title\n","# =========================================================\n","# 3. Model: Attention Residual U-Net (ARU-Net)\n","# =========================================================\n","class ResidualBlock(nn.Module): # thing about it to renamed. we maybe changed it.\n","    def __init__(self, channels):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n","\n","    def forward(self, x):\n","        res = x\n","        out = self.relu(self.conv1(x))\n","        out = self.conv2(out)\n","        return self.relu(out + res)\n","\n","\n","class AttentionBlock(nn.Module): # we can change it to make unique.\n","    def __init__(self, F_g, F_l, F_int):\n","        super().__init__()\n","        self.W_g = nn.Sequential(nn.Conv2d(F_g, F_int, kernel_size=1), nn.BatchNorm2d(F_int))\n","        self.W_x = nn.Sequential(nn.Conv2d(F_l, F_int, kernel_size=1), nn.BatchNorm2d(F_int))\n","        self.psi = nn.Sequential(nn.Conv2d(F_int, 1, kernel_size=1), nn.BatchNorm2d(1), nn.Sigmoid())\n","        self.relu = nn.ReLU(inplace=True)\n","\n","    def forward(self, g, x):\n","        psi = self.relu(self.W_g(g) + self.W_x(x))\n","        psi = self.psi(psi)\n","        return x * psi\n","\n","\n","class AttentionResidualUNet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        # Encoder\n","        self.enc1 = nn.Sequential(nn.Conv2d(3, 64, 3, 1, 1), nn.ReLU(True),\n","                                  nn.Conv2d(64, 64, 3, 1, 1), nn.ReLU(True),\n","                                  ResidualBlock(64))\n","        self.pool1 = nn.MaxPool2d(2)\n","\n","        self.enc2 = nn.Sequential(nn.Conv2d(64, 128, 3, 1, 1), nn.ReLU(True),\n","                                  nn.Conv2d(128, 128, 3, 1, 1), nn.ReLU(True),\n","                                  ResidualBlock(128))\n","        self.pool2 = nn.MaxPool2d(2)\n","\n","        self.enc3 = nn.Sequential(nn.Conv2d(128, 256, 3, 1, 1), nn.ReLU(True),\n","                                  nn.Conv2d(256, 256, 3, 1, 1), nn.ReLU(True),\n","                                  ResidualBlock(256))\n","        self.pool3 = nn.MaxPool2d(2)\n","\n","        self.enc4 = nn.Sequential(nn.Conv2d(256, 512, 3, 1, 1), nn.ReLU(True),\n","                                  nn.Conv2d(512, 512, 3, 1, 1), nn.ReLU(True),\n","                                  ResidualBlock(512))\n","        self.pool4 = nn.MaxPool2d(2)\n","\n","        # Center\n","        self.center = nn.Sequential(nn.Conv2d(512, 1024, 3, 1, 1), nn.ReLU(True), ResidualBlock(1024))\n","\n","        # Attention gates\n","        self.att4 = AttentionBlock(512, 512, 256)\n","        self.att3 = AttentionBlock(256, 256, 128)\n","        self.att2 = AttentionBlock(128, 128, 64)\n","        self.att1 = AttentionBlock(64, 64, 32)\n","\n","        # Decoder\n","        self.up4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n","        self.dec4 = nn.Sequential(nn.Conv2d(1024, 512, 3, 1, 1), nn.ReLU(True), ResidualBlock(512))\n","\n","        self.up3 = nn.ConvTranspose2d(512, 256, 2, 2)\n","        self.dec3 = nn.Sequential(nn.Conv2d(512, 256, 3, 1, 1), nn.ReLU(True), ResidualBlock(256))\n","\n","        self.up2 = nn.ConvTranspose2d(256, 128, 2, 2)\n","        self.dec2 = nn.Sequential(nn.Conv2d(256, 128, 3, 1, 1), nn.ReLU(True), ResidualBlock(128))\n","\n","        self.up1 = nn.ConvTranspose2d(128, 64, 2, 2)\n","        self.dec1 = nn.Sequential(nn.Conv2d(128, 64, 3, 1, 1), nn.ReLU(True), ResidualBlock(64))\n","\n","        self.out = nn.Conv2d(64, 3, kernel_size=1)\n","\n","    def forward(self, x):\n","        e1 = self.enc1(x); p1 = self.pool1(e1)\n","        e2 = self.enc2(p1); p2 = self.pool2(e2)\n","        e3 = self.enc3(p2); p3 = self.pool3(e3)\n","        e4 = self.enc4(p3); p4 = self.pool4(e4)\n","        c = self.center(p4)\n","\n","        d4 = self.up4(c)\n","        e4_att = self.att4(d4, e4)\n","        d4 = self.dec4(torch.cat([d4, e4_att], dim=1))\n","\n","        d3 = self.up3(d4)\n","        e3_att = self.att3(d3, e3)\n","        d3 = self.dec3(torch.cat([d3, e3_att], dim=1))\n","\n","        d2 = self.up2(d3)\n","        e2_att = self.att2(d2, e2)\n","        d2 = self.dec2(torch.cat([d2, e2_att], dim=1))\n","\n","        d1 = self.up1(d2)\n","        e1_att = self.att1(d1, e1)\n","        d1 = self.dec1(torch.cat([d1, e1_att], dim=1))\n","\n","        return torch.sigmoid(self.out(d1))"]},{"cell_type":"markdown","metadata":{"id":"CKZ8qgfz-lD1"},"source":["# 4. Mask Utilities leaf mask from clean image"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"x5UEW3ZL-o_k","executionInfo":{"status":"ok","timestamp":1762436910258,"user_tz":-360,"elapsed":26,"user":{"displayName":"Mobashara Mobashara","userId":"14068009748502855723"}}},"outputs":[],"source":["# @title\n","# =========================================================\n","# 4. Mask Utilities (Leaf Mask from Clean Image)\n","# =========================================================\n","def create_leaf_mask_from_rgb_tensor(img_rgb, low_h=0.18, high_h=0.45, min_sat=0.15, min_val=0.05):\n","    \"\"\"\n","    Create a soft binary mask for leaf regions from an RGB tensor.\n","    - img_rgb: (B,3,H,W), values in [0,1]\n","    - Hues selected around green (default approx 0.18..0.45 in 0..1)\n","    Returns: mask (B,1,H,W) float in {0,1}\n","    \"\"\"\n","    # convert to HSV using kornia (expects float tensor 0..1)\n","    hsv = rgb_to_hsv(img_rgb)  # returns (B,3,H,W): h,s,v in [0,1]\n","    h = hsv[:, 0:1, :, :]  # (B,1,H,W)\n","    s = hsv[:, 1:2, :, :]\n","    v = hsv[:, 2:3, :, :]\n","\n","    # handle hue wrap-around (not needed for green but robust)\n","    # keep hue between low_h and high_h\n","    mask_h = (h >= low_h) & (h <= high_h)\n","    mask_sv = (s >= min_sat) & (v >= min_val)\n","    mask = (mask_h & mask_sv).float()\n","\n","    # optional: morphological smoothing (Gaussian blur) to reduce noisy tiny bits\n","    # Use kornia median blur with small kernel\n","    try:\n","        mask = kornia.filters.median_blur(mask, (3, 3))\n","    except Exception:\n","        # fallback: no filtering if kornia version differs\n","        pass\n","\n","    return mask  # (B,1,H,W)"]},{"cell_type":"markdown","metadata":{"id":"tATT48mMxC8f"},"source":["# 5. Loss: Combined (Perceptual + SSIM + Edge + L1)"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"dxQGI08sxEBb","executionInfo":{"status":"ok","timestamp":1762436916251,"user_tz":-360,"elapsed":34,"user":{"displayName":"Mobashara Mobashara","userId":"14068009748502855723"}}},"outputs":[],"source":["# @title\n","# =========================================================\n","# 5. Loss: Combined (Perceptual + L1 + Edge + Masked SSIM)\n","# =========================================================\n","class CombinedLoss(nn.Module):\n","    def __init__(self, device='cpu', use_vgg=True):\n","        super().__init__()\n","        self.device = device\n","        self.use_vgg = use_vgg\n","        if use_vgg:\n","            vgg = models.vgg16(pretrained=True).features[:16].eval().to(device)\n","            for p in vgg.parameters():\n","                p.requires_grad = False\n","            self.vgg = vgg\n","        self.ssim = StructuralSimilarityIndexMeasure(data_range=1.0).to(device)\n","        self.laplace = kornia.filters.Laplacian(3)\n","\n","    def forward(self, output, target, mask=None):\n","        output = torch.clamp(output, 0.0, 1.0)\n","        target = torch.clamp(target, 0.0, 1.0)\n","        if mask is None:\n","            with torch.no_grad():\n","                mask = create_leaf_mask_from_rgb_tensor(target)  # (B,1,H,W)\n","        if mask.dim() == 3:\n","            mask = mask.unsqueeze(1)\n","        if mask.shape[1] == 1 and output.shape[1] == 3:\n","            mask_rgb = mask.repeat(1, 3, 1, 1)\n","        else:\n","            mask_rgb = mask\n","        content_loss = F.l1_loss(self.vgg(output), self.vgg(target)) if self.use_vgg else 0.0\n","        pixel_loss = F.l1_loss(output, target)\n","        edge_loss = F.l1_loss(self.laplace(output), self.laplace(target))\n","        output_masked = output * mask_rgb\n","        target_masked = target * mask_rgb\n","        if mask_rgb.sum() <= 1e-6:\n","            ssim_value = self.ssim(output, target).mean()\n","        else:\n","            ssim_value = self.ssim(output_masked, target_masked).mean()\n","\n","        ssim_loss = 1.0 - ssim_value\n","\n","        total = 0.4 * pixel_loss + 0.25 * content_loss + 0.2 * edge_loss + 0.15 * ssim_loss\n","        return total"]},{"cell_type":"markdown","metadata":{"id":"J9L9twTHxG9W"},"source":["# 6. Training Function"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"E8DVD2JNxVVQ","executionInfo":{"status":"ok","timestamp":1762436922242,"user_tz":-360,"elapsed":52,"user":{"displayName":"Mobashara Mobashara","userId":"14068009748502855723"}}},"outputs":[],"source":["# @title\n","# =========================================================\n","# 6. Training Function (with epoch-wise CSV logging)\n","# =========================================================\n","def train(model, train_loader, val_loader, device, epochs=70, lr=1e-4, optimizer=None, scheduler=None, save_dir=\"./Output\"):\n","    print(\"ðŸš€ Starting Training (Masked SSIM)...\")\n","    os.makedirs(save_dir, exist_ok=True)\n","    csv_path = os.path.join(save_dir, \"training_validation_metrics.csv\")\n","\n","    criterion = CombinedLoss(device=device, use_vgg=True)\n","    if optimizer is None:\n","        optimizer = optim.Adam(model.parameters(), lr=lr)\n","    if scheduler is None:\n","        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n","    scaler = torch.cuda.amp.GradScaler() if 'cuda' in device else None\n","\n","    # Initialize CSV file\n","    with open(csv_path, \"w\", newline=\"\") as f:\n","        writer = csv.writer(f)\n","        writer.writerow([\"epoch\", \"train_loss\", \"train_psnr\", \"train_ssim\", \"val_loss\", \"val_psnr\", \"val_ssim\"])\n","\n","    model.train()\n","    train_losses = []\n","\n","    for epoch in range(epochs):\n","        print(f\"\\nðŸ“ˆ Epoch {epoch+1}/{epochs}\")\n","        running_loss = 0.0\n","        skipped_batches = 0\n","\n","        # ================= Training ==================\n","        for batch_idx, batch in enumerate(train_loader):\n","            if len(batch) == 3:\n","                dist_img, clean_img, _ = batch\n","            else:\n","                dist_img, clean_img = batch\n","            dist_img, clean_img = dist_img.to(device), clean_img.to(device)\n","\n","            if dist_img.shape != clean_img.shape:\n","                skipped_batches += 1\n","                continue\n","\n","            optimizer.zero_grad()\n","            if scaler:\n","                with torch.amp.autocast('cuda'):\n","                    output = model(dist_img)\n","                    if output.shape != clean_img.shape:\n","                        output = F.interpolate(output, size=clean_img.shape[2:], mode='bilinear', align_corners=False)\n","                    loss = criterion(output, clean_img, None)\n","                scaler.scale(loss).backward()\n","                scaler.step(optimizer)\n","                scaler.update()\n","            else:\n","                output = model(dist_img)\n","                if output.shape != clean_img.shape:\n","                    output = F.interpolate(output, size=clean_img.shape[2:], mode='bilinear', align_corners=False)\n","                loss = criterion(output, clean_img, None)\n","                loss.backward()\n","                optimizer.step()\n","\n","            running_loss += loss.item()\n","            if batch_idx % 10 == 0:\n","                print(f\"   Batch {batch_idx:4d}, Loss: {loss.item():.6f}\")\n","\n","        scheduler.step()\n","        avg_train_loss = running_loss / (len(train_loader) - skipped_batches)\n","        train_losses.append(avg_train_loss)\n","\n","        # ================= Validation ==================\n","        model.eval()\n","        val_loss, val_psnr_list, val_ssim_list = 0.0, [], []\n","\n","        with torch.no_grad():\n","            for val_batch in val_loader:\n","                if len(val_batch) == 3:\n","                    dist_img, clean_img, _ = val_batch\n","                else:\n","                    dist_img, clean_img = val_batch\n","                dist_img, clean_img = dist_img.to(device), clean_img.to(device)\n","\n","                output = model(dist_img)\n","                if output.shape != clean_img.shape:\n","                    output = F.interpolate(output, size=clean_img.shape[2:], mode='bilinear', align_corners=False)\n","                loss = criterion(output, clean_img, None)\n","                val_loss += loss.item()\n","\n","                output_np = output.detach().cpu().numpy().transpose(0, 2, 3, 1)\n","                target_np = clean_img.cpu().numpy().transpose(0, 2, 3, 1)\n","\n","                for i in range(output_np.shape[0]):\n","                    pred = np.clip(output_np[i], 0, 1)\n","                    target = np.clip(target_np[i], 0, 1)\n","                    val_psnr_list.append(psnr_sk(target, pred, data_range=1.0))\n","                    val_ssim_list.append(ssim_sk(target, pred, channel_axis=-1, data_range=1.0))\n","\n","        avg_val_loss = val_loss / len(val_loader)\n","        avg_val_psnr = np.mean(val_psnr_list)\n","        avg_val_ssim = np.mean(val_ssim_list)\n","\n","        # Compute PSNR/SSIM on train (small sample)\n","        train_psnr_list, train_ssim_list = [], []\n","        with torch.no_grad():\n","            for dist_img, clean_img, _ in train_loader:\n","                dist_img, clean_img = dist_img.to(device), clean_img.to(device)\n","                output = model(dist_img)\n","                output_np = output.detach().cpu().numpy().transpose(0, 2, 3, 1)\n","                target_np = clean_img.cpu().numpy().transpose(0, 2, 3, 1)\n","                for i in range(output_np.shape[0]):\n","                    train_psnr_list.append(psnr_sk(target_np[i], output_np[i], data_range=1.0))\n","                    train_ssim_list.append(ssim_sk(target_np[i], output_np[i], channel_axis=-1, data_range=1.0))\n","                break  # only one batch for speed\n","        avg_train_psnr = np.mean(train_psnr_list)\n","        avg_train_ssim = np.mean(train_ssim_list)\n","\n","        # Save metrics to CSV\n","        with open(csv_path, \"a\", newline=\"\") as f:\n","            writer = csv.writer(f)\n","            writer.writerow([\n","                epoch + 1,\n","                avg_train_loss,\n","                avg_train_psnr,\n","                avg_train_ssim,\n","                avg_val_loss,\n","                avg_val_psnr,\n","                avg_val_ssim\n","            ])\n","\n","        print(f\"âœ… Epoch {epoch+1} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | \"\n","              f\"Train PSNR: {avg_train_psnr:.2f} | Val PSNR: {avg_val_psnr:.2f}\")\n","\n","        model.train()  # set back to train mode\n","\n","    print(f\"\\nâœ… Training Complete! Metrics saved to {csv_path}\")\n","    return train_losses\n"]},{"cell_type":"markdown","metadata":{"id":"Jiw0NPNixWY2"},"source":["# 7. Evaluation, Metrics Saving & Visualization Utilities\n"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"3XL3XfwyxX2M","executionInfo":{"status":"ok","timestamp":1762436926206,"user_tz":-360,"elapsed":78,"user":{"displayName":"Mobashara Mobashara","userId":"14068009748502855723"}}},"outputs":[],"source":["# @title\n","# =========================================================\n","# 7. Evaluation, Metrics Saving & Visualization - FIXED (win_size + scoping issues)\n","# =========================================================\n","def evaluate(model, dataloader, device, save_dir=\"./Output\"):\n","    print(\"\\nðŸ§ª Starting Evaluation (masked SSIM for each image)...\")\n","    os.makedirs(save_dir, exist_ok=True)\n","    csv_path = os.path.join(save_dir, \"eval_metricsmetrics.csv\")\n","\n","    model.eval()\n","    psnr_scores, ssim_scores = [], []\n","    csv_rows = []\n","\n","    with torch.no_grad():\n","        idx_counter = 0\n","        for batch_idx, batch in enumerate(dataloader):\n","            if len(batch) == 3:\n","                dist_img, clean_img, paths = batch\n","            else:\n","                dist_img, clean_img = batch\n","                paths = [f\"sample_{i}\" for i in range(dist_img.shape[0])]\n","\n","            dist_img, clean_img = dist_img.to(device), clean_img.to(device)\n","\n","            # Forward pass (with AMP if CUDA)\n","            if 'cuda' in device:\n","                with torch.amp.autocast('cuda'):\n","                    output = model(dist_img)\n","            else:\n","                output = model(dist_img)\n","\n","            # Resize and clamp\n","            if output.shape != clean_img.shape:\n","                output = torch.nn.functional.interpolate(output, size=clean_img.shape[2:], mode='bilinear', align_corners=False)\n","            output = torch.clamp(output, 0, 1)\n","\n","            # Convert to numpy for metrics\n","            output_np = output.cpu().numpy().transpose(0, 2, 3, 1)\n","            clean_np = clean_img.cpu().numpy().transpose(0, 2, 3, 1)\n","            mask_tensor = create_leaf_mask_from_rgb_tensor(clean_img)\n","            mask_np = mask_tensor.cpu().numpy().transpose(0, 2, 3, 1)\n","\n","            for i in range(output_np.shape[0]):\n","                pred = np.clip(output_np[i], 0, 1)\n","                target = np.clip(clean_np[i], 0, 1)\n","                mask_i = (mask_np[i, :, :, 0] > 0.5).astype(np.float32)\n","\n","                # Compute PSNR + SSIM (masked or global)\n","                if mask_i.sum() < 49:\n","                    psnr_val = psnr_sk(target, pred, data_range=1.0)\n","                    ssim_val = ssim_sk(target, pred, channel_axis=-1, data_range=1.0)\n","                else:\n","                    ys, xs = np.where(mask_i)\n","                    y0, y1 = ys.min(), ys.max()\n","                    x0, x1 = xs.min(), xs.max()\n","                    crop_h, crop_w = y1 - y0 + 1, x1 - x0 + 1\n","\n","                    if crop_h < 7 or crop_w < 7:\n","                        psnr_val = psnr_sk(target, pred, data_range=1.0)\n","                        ssim_val = ssim_sk(target, pred, channel_axis=-1, data_range=1.0)\n","                    else:\n","                        pred_crop = pred[y0:y1+1, x0:x1+1, :]\n","                        target_crop = target[y0:y1+1, x0:x1+1, :]\n","                        win_size = min(7, min(crop_h, crop_w))\n","                        if win_size % 2 == 0: win_size -= 1\n","                        if win_size < 3: win_size = 3\n","                        psnr_val = psnr_sk(target_crop, pred_crop, data_range=1.0)\n","                        try:\n","                            ssim_val = ssim_sk(target_crop, pred_crop, channel_axis=-1, data_range=1.0, win_size=win_size)\n","                        except ValueError:\n","                            ssim_val = ssim_sk(target, pred, channel_axis=-1, data_range=1.0)\n","\n","                psnr_scores.append(psnr_val)\n","                ssim_scores.append(ssim_val)\n","                csv_rows.append([idx_counter, psnr_val, ssim_val])\n","\n","                # âœ… Save reconstructed image only\n","                recon_name = f\"Image_{idx_counter}_Reconstructed.jpg\"\n","                save_path = os.path.join(save_dir, recon_name)\n","                save_image(torch.from_numpy(pred.transpose(2, 0, 1)), save_path)\n","\n","                idx_counter += 1\n","\n","            if batch_idx % 5 == 0:\n","                print(f\"   Processed batch {batch_idx}\")\n","\n","    # Write CSV\n","    with open(csv_path, \"w\", newline=\"\") as f:\n","        writer = csv.writer(f)\n","        writer.writerow([\"Index\", \"PSNR\", \"SSIM\"])\n","        writer.writerows(csv_rows)\n","\n","    if len(psnr_scores) == 0:\n","        print(\"âš ï¸ No valid samples evaluated!\")\n","        return 0.0, 0.0, [], []\n","\n","    print(f\"\\nðŸ“Š Evaluation Results:\")\n","    print(f\"   PSNR (mean Â± std):  {np.mean(psnr_scores):.4f} Â± {np.std(psnr_scores):.4f}\")\n","    print(f\"   SSIM (mean Â± std):  {np.mean(ssim_scores):.4f} Â± {np.std(ssim_scores):.4f}\")\n","    print(f\"   Saved {len(psnr_scores)} reconstructed images and metrics to: {csv_path}\")\n","\n","    return np.mean(psnr_scores), np.mean(ssim_scores), psnr_scores, ssim_scores\n","\n","\n","def visualize_training_progress(train_losses):\n","    if not train_losses:\n","        print(\"âš ï¸ No training losses to visualize!\")\n","        return\n","    plt.figure(figsize=(10, 6))\n","    plt.plot(range(1, len(train_losses) + 1), train_losses, linewidth=2)\n","    plt.title('Training Loss Progress', fontsize=14, fontweight='bold')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.grid(True, alpha=0.3)\n","    plt.show()\n","    print(f\"ðŸ“ˆ Initial Loss: {train_losses[0]:.6f}, Final Loss: {train_losses[-1]:.6f}\")\n","\n","\n","def visualize_sample_results(model, dataloader, device, num_samples=3, save_dir=None):\n","    model.eval()\n","    samples_collected = 0\n","    with torch.no_grad():\n","        for batch in dataloader:  # No batch_idx here; use samples_collected instead\n","            if len(batch) == 3:\n","                dist_img, clean_img, paths = batch\n","            else:\n","                dist_img, clean_img = batch\n","                paths = [f\"sample_{i}\" for i in range(dist_img.shape[0])]\n","\n","            dist_img, clean_img = dist_img.to(device), clean_img.to(device)\n","            output = model(dist_img)\n","            if output.shape != clean_img.shape:\n","                output = torch.nn.functional.interpolate(output, size=clean_img.shape[2:], mode='bilinear', align_corners=False)\n","\n","            # Compute masks for visualization (inside this function)\n","            mask_tensor = create_leaf_mask_from_rgb_tensor(clean_img)  # (B,1,H,W)\n","            mask_np = mask_tensor.cpu().numpy().transpose(0, 2, 3, 1)  # (B,H,W,1)\n","\n","            for i in range(dist_img.shape[0]):\n","                if samples_collected >= num_samples:\n","                    return\n","\n","                dist_np = dist_img[i].cpu().numpy().transpose(1, 2, 0)\n","                out_np = output[i].cpu().numpy().transpose(1, 2, 0)\n","                clean_np = clean_img[i].cpu().numpy().transpose(1, 2, 0)\n","\n","                pred = np.clip(out_np, 0, 1)\n","                target = np.clip(clean_np, 0, 1)\n","\n","                # Compute mask_i for this sample (for debug print/viz)\n","                mask_i = (mask_np[i, :, :, 0] > 0.5).astype(np.float32)\n","\n","                plt.figure(figsize=(12, 4))\n","                plt.subplot(1, 3, 1); plt.imshow(np.clip(dist_np, 0, 1)); plt.title('Distorted'); plt.axis('off')\n","                plt.subplot(1, 3, 2); plt.imshow(pred); plt.title('Reconstructed'); plt.axis('off')\n","                plt.subplot(1, 3, 3); plt.imshow(target); plt.title('Original'); plt.axis('off')\n","                plt.tight_layout(); plt.show()\n","\n","                if save_dir:\n","                    os.makedirs(save_dir, exist_ok=True)\n","                    filename = os.path.basename(paths[i]) if isinstance(paths[i], str) else f\"sample_{samples_collected}.png\"\n","                    recon_path = os.path.join(save_dir, f\"recon_{filename}\")\n","                    plt.imsave(recon_path, pred)\n","                    print(f\"   Saved: {recon_path}\")\n","\n","                # DEBUG: Visualize mask and print area for first sample only\n","                if samples_collected == 0:\n","                    plt.figure(figsize=(6, 6))\n","                    plt.imshow(mask_np[i, :, :, 0], cmap='gray')\n","                    plt.title('Leaf Mask (White = Leaf Region)')\n","                    plt.axis('off')\n","                    plt.show()\n","                    print(f\"Mask area (pixels): {mask_i.sum()}\")  # Print size\n","\n","                samples_collected += 1\n","\n","\n","def save_training_results(train_losses, psnr_score, ssim_score, filename=\"training_results.json\"):\n","    if not train_losses:\n","        print(\"âš ï¸ No results to save!\")\n","        return\n","    results = {\n","        'train_losses': [float(loss) for loss in train_losses],\n","        'final_psnr': float(psnr_score),\n","        'final_ssim': float(ssim_score),\n","        'epochs': len(train_losses)\n","    }\n","    with open(filename, 'w') as f:\n","        json.dump(results, f, indent=2)\n","    print(f\"âœ… Training results saved to {filename}\")\n","\n","\n","def save_metrics_csv(model, dataloader, device, save_path):\n","    model.eval()\n","    records = []\n","    with torch.no_grad():\n","        for batch in dataloader:\n","            if len(batch) == 3:\n","                dist_img, clean_img, paths = batch\n","            else:\n","                dist_img, clean_img = batch\n","                paths = [f\"sample_{i}\" for i in range(dist_img.shape[0])]\n","\n","            dist_img, clean_img = dist_img.to(device), clean_img.to(device)\n","            output = model(dist_img)\n","            if output.shape != clean_img.shape:\n","                output = torch.nn.functional.interpolate(output, size=clean_img.shape[2:], mode='bilinear', align_corners=False)\n","\n","            # Convert to numpy once per batch\n","            output_np = output.cpu().numpy().transpose(0, 2, 3, 1)\n","            clean_np = clean_img.cpu().numpy().transpose(0, 2, 3, 1)\n","\n","            # Create masks (add this for masked metrics)\n","            mask_tensor = create_leaf_mask_from_rgb_tensor(clean_img)  # (B,1,H,W)\n","            mask_np = mask_tensor.cpu().numpy().transpose(0, 2, 3, 1)  # (B,H,W,1)\n","\n","            for i in range(dist_img.shape[0]):\n","                pred = np.clip(output_np[i], 0, 1)\n","                target = np.clip(clean_np[i], 0, 1)\n","                mask_i = (mask_np[i, :, :, 0] > 0.5).astype(np.float32)  # binary HxW\n","\n","                # If mask too small, fallback to global\n","                if mask_i.sum() < 49:  # 7x7 min\n","                    psnr_val = psnr_sk(target, pred, data_range=1.0)\n","                    ssim_val = ssim_sk(target, pred, channel_axis=-1, data_range=1.0)  # Global, no issue\n","                else:\n","                    ys, xs = np.where(mask_i)\n","                    if ys.size == 0:\n","                        psnr_val = psnr_sk(target, pred, data_range=1.0)\n","                        ssim_val = ssim_sk(target, pred, channel_axis=-1, data_range=1.0)\n","                    else:\n","                        y0, y1 = ys.min(), ys.max()\n","                        x0, x1 = xs.min(), xs.max()\n","                        crop_h, crop_w = y1 - y0 + 1, x1 - x0 + 1\n","                        if crop_h < 7 or crop_w < 7:\n","                            psnr_val = psnr_sk(target, pred, data_range=1.0)\n","                            ssim_val = ssim_sk(target, pred, channel_axis=-1, data_range=1.0)\n","                        else:\n","                            pred_crop = pred[y0:y1+1, x0:x1+1, :]\n","                            target_crop = target[y0:y1+1, x0:x1+1, :]\n","\n","                            # Dynamic win_size\n","                            win_size = min(7, min(crop_h, crop_w))\n","                            if win_size % 2 == 0: win_size -= 1\n","                            if win_size < 3: win_size = 3\n","\n","                            psnr_val = psnr_sk(target_crop, pred_crop, data_range=1.0)\n","                            try:\n","                                ssim_val = ssim_sk(target_crop, pred_crop, channel_axis=-1, data_range=1.0, win_size=win_size)\n","                            except ValueError:\n","                                ssim_val = ssim_sk(target, pred, channel_axis=-1, data_range=1.0)\n","\n","                records.append({\n","                    \"filename\": os.path.basename(paths[i]) if isinstance(paths[i], str) else f\"sample_{i}\",\n","                    \"PSNR\": float(psnr_val),\n","                    \"SSIM\": float(ssim_val)\n","                })\n","    df = pd.DataFrame(records)\n","    df.to_csv(save_path, index=False)\n","    print(f\"Metrics saved to {save_path}\")\n","    return df"]},{"cell_type":"markdown","metadata":{"id":"VXHXVVA8xezm"},"source":["# 8. Main Execution Pipeline (Example)"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"62OHalwkxgE5","colab":{"base_uri":"https://localhost:8080/","height":365},"executionInfo":{"status":"error","timestamp":1762436933924,"user_tz":-360,"elapsed":110,"user":{"displayName":"Mobashara Mobashara","userId":"14068009748502855723"}},"outputId":"61157390-5e0b-4304-f68b-0a5690b4f221"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/MyDrive/FrameReconstruction/dataset/Noise_Multiply_Strong'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2803111940.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m# 3. Full dataset (no transform) + split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m# --------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mfull_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImagePairDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistorted_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Total paired images: {N}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-3931104211.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, distorted_dir, clean_dir, transform, dist_suffix, clean_suffix)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         distorted_filenames = sorted([\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistorted_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".jpg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".jpeg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         ])\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/FrameReconstruction/dataset/Noise_Multiply_Strong'"]}],"source":["# @title\n","# =========================================================\n","# 8. Main Execution â€“ 80/10/10 + FULL-RES RECONSTRUCTIONS (ALL SPLITS)\n","# =========================================================\n","if __name__ == \"__main__\":\n","    # --------------------------------------------------------------\n","    # 0. Device\n","    # --------------------------------------------------------------\n","    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","    print(f\"Using device: {device}\")\n","\n","    # --------------------------------------------------------------\n","    # 1. Paths & folders\n","    # --------------------------------------------------------------\n","    dataset_name      = \"Noise_Multiply_Strong\" #\n","\n","    save_model_folder = \"/content/drive/MyDrive/FrameReconstruction/Save_Model\" # .pth model eta save korar jann\n","\n","    distorted_dir     = \"/content/drive/MyDrive/FrameReconstruction/dataset/Noise_Multiply_Strong\" # noise folder\n","\n","    clean_dir         = \"/content/drive/MyDrive/FrameReconstruction/dataset/Orginal\" # fixed eta change hobe na.\n","\n","    custom_save_dir   = \"/content/drive/MyDrive/FrameReconstruction/Output/Noise_Multiply_Strong\" # Reconstructed all image will saved here\n","\n","    os.makedirs(save_model_folder, exist_ok=True)\n","    os.makedirs(custom_save_dir,   exist_ok=True)\n","\n","    recon_all_dir = os.path.join(custom_save_dir, \"reconstructed_all\")\n","    samples_dir   = os.path.join(custom_save_dir, \"samples\")\n","    os.makedirs(recon_all_dir, exist_ok=True)\n","    os.makedirs(samples_dir,   exist_ok=True)\n","\n","    # --------------------------------------------------------------\n","    # 2. Transforms (train: 224Ã—224 patch | eval: full size)\n","    # --------------------------------------------------------------\n","    train_transform = transforms.Compose([\n","        transforms.RandomResizedCrop(224),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.RandomRotation(5),\n","        transforms.ColorJitter(brightness=0.1, contrast=0.1),\n","        transforms.ToTensor(),\n","    ])\n","    eval_transform = transforms.Compose([transforms.ToTensor()])\n","\n","    # --------------------------------------------------------------\n","    # 3. Full dataset (no transform) + split\n","    # --------------------------------------------------------------\n","    full_dataset = ImagePairDataset(distorted_dir, clean_dir, transform=None)\n","    N = len(full_dataset)\n","    print(f\"Total paired images: {N}\")\n","\n","    train_N = int(0.8 * N)\n","    val_N   = int(0.1 * N)\n","    test_N  = N - train_N - val_N\n","\n","    torch.manual_seed(42)\n","    train_idx, val_idx, test_idx = torch.utils.data.random_split(\n","        range(N), [train_N, val_N, test_N]\n","    )\n","\n","    # --------------------------------------------------------------\n","    # 4. Wrapper to apply correct transform per split\n","    # --------------------------------------------------------------\n","    class TransformDataset(torch.utils.data.Dataset):\n","        def __init__(self, base_dataset, indices, transform):\n","            self.base = base_dataset\n","            self.idx  = indices\n","            self.transform = transform\n","\n","        def __len__(self): return len(self.idx)\n","\n","        def __getitem__(self, i):\n","            idx = self.idx[i]\n","            dist_path, clean_path = self.base.data_pairs[idx]\n","            dist_img = Image.open(dist_path).convert(\"RGB\")\n","            clean_img = Image.open(clean_path).convert(\"RGB\")\n","\n","            seed = np.random.randint(2147483647)\n","            torch.manual_seed(seed)\n","            dist_tensor = self.transform(dist_img) if self.transform else transforms.ToTensor()(dist_img)\n","            torch.manual_seed(seed)\n","            clean_tensor = self.transform(clean_img) if self.transform else transforms.ToTensor()(clean_img)\n","\n","            return dist_tensor, clean_tensor, dist_path\n","\n","    train_dataset = TransformDataset(full_dataset, train_idx.indices, train_transform)\n","    val_dataset   = TransformDataset(full_dataset, val_idx.indices,   eval_transform)\n","    test_dataset  = TransformDataset(full_dataset, test_idx.indices,  eval_transform)\n","\n","    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True,  num_workers=2)\n","    val_loader   = DataLoader(val_dataset,   batch_size=1, shuffle=False, num_workers=2)\n","    test_loader  = DataLoader(test_dataset,  batch_size=1, shuffle=False, num_workers=2)\n","\n","    print(f\"Train / Val / Test â†’ {len(train_dataset)} / {len(val_dataset)} / {len(test_dataset)}\")\n","\n","    # --------------------------------------------------------------\n","    # 5. Model, optimizer, scheduler\n","    # --------------------------------------------------------------\n","    model = AttentionResidualUNet().to(device)\n","    print(f\"Model params: {sum(p.numel() for p in model.parameters()):,}\")\n","\n","    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n","    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.5)\n","\n","    # --------------------------------------------------------------\n","    # 6. TRAIN (with early stopping)\n","    # --------------------------------------------------------------\n","    train_losses = train(\n","        model, train_loader, val_loader, device,\n","        epochs=150, optimizer=optimizer, scheduler=scheduler,\n","        save_dir=custom_save_dir, patience=20\n","    )\n","\n","    # --------------------------------------------------------------\n","    # 7. SAVE ALL RECONSTRUCTIONS + PER-IMAGE METRICS (TRAIN + VAL + TEST)\n","    # --------------------------------------------------------------\n","    print(\"\\n=== SAVING FULL-RES RECONSTRUCTIONS + METRICS FOR ALL SPLITS ===\")\n","\n","    def save_split_reconstructions(loader, split_name, recon_dir):\n","        csv_path = os.path.join(custom_save_dir, f\"metrics_{split_name}.csv\")\n","        rows = []\n","        model.eval()\n","        with torch.no_grad():\n","            for dist_img, clean_img, path in tqdm(loader, desc=f\"[{split_name.upper()}]\"):\n","                dist_img  = dist_img.to(device)\n","                clean_img = clean_img.to(device)\n","\n","                out = model(dist_img)\n","                if out.shape[2:] != clean_img.shape[2:]:\n","                    out = F.interpolate(out, size=clean_img.shape[2:], mode='bilinear', align_corners=False)\n","                out = torch.clamp(out, 0, 1)\n","\n","                for i in range(out.shape[0]):\n","                    pred_np  = out[i].cpu().numpy().transpose(1, 2, 0)\n","                    clean_np = clean_img[i].cpu().numpy().transpose(1, 2, 0)\n","\n","                    psnr_val = psnr_sk(clean_np, pred_np, data_range=1.0)\n","                    ssim_val = ssim_sk(clean_np, pred_np, channel_axis=-1, data_range=1.0)\n","\n","                    base = os.path.splitext(os.path.basename(path[i]))[0]\n","                    img_path = os.path.join(recon_dir, f\"{base}_{split_name}_recon.png\")\n","                    Image.fromarray((pred_np * 255).astype(np.uint8)).save(img_path)\n","\n","                    rows.append([base, psnr_val, ssim_val, img_path])\n","\n","        pd.DataFrame(rows, columns=[\"filename\", \"PSNR\", \"SSIM\", \"recon_path\"]).to_csv(csv_path, index=False)\n","        print(f\"{split_name.upper()} â†’ {csv_path}\")\n","        print(f\"   Avg PSNR: {np.mean([r[1] for r in rows]):.3f} | Avg SSIM: {np.mean([r[2] for r in rows]):.3f}\")\n","\n","    # Run on all splits\n","    save_split_reconstructions(train_loader, \"train\", recon_all_dir)\n","    save_split_reconstructions(val_loader,   \"val\",   recon_all_dir)\n","    save_split_reconstructions(test_loader,  \"test\",  recon_all_dir)\n","\n","    # --------------------------------------------------------------\n","    # 8. Optional: visualize a few samples\n","    # --------------------------------------------------------------\n","    visualize_sample_results(model, test_loader, device, num_samples=5, save_dir=samples_dir)\n","\n","    # --------------------------------------------------------------\n","    # 9. Save final model\n","    # --------------------------------------------------------------\n","    final_path = os.path.join(save_model_folder, f\"{dataset_name}_AttentionResidualUNet_final.pth\")\n","    torch.save(model.state_dict(), final_path)\n","    print(f\"\\nFinal model saved â†’ {final_path}\")\n","\n","    # --------------------------------------------------------------\n","    # DONE\n","    # --------------------------------------------------------------\n","    print(\"\\nAll done! Check:\")\n","    print(f\"   â€¢ Reconstructed images â†’ {recon_all_dir}\")\n","    print(f\"   â€¢ Metrics CSVs â†’ {custom_save_dir}/metrics_*.csv\")"]},{"cell_type":"markdown","metadata":{"id":"6ugK2Jqsh-kF"},"source":["# Plot Random Sample with Metrices Overlay"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4mJjQL7K75V9"},"outputs":[],"source":["# @title\n","distorted_dir = \"Noisy | Blur image Folder link\"\n","clean_dir = \"your Original image folder link\"\n","custom_save_dir = \"Your output folder link\""]},{"cell_type":"markdown","metadata":{"id":"WmbO-GNLiRBk"},"source":["# Plot SSIM & PSNR"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KN3i35jEiSZC","cellView":"form"},"outputs":[],"source":["# @title\n","# =========================================================\n","# Bonus: Visualize SSIM and PSNR Metrics from Saved CSVs\n","# =========================================================\n","import os\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","eval_csv_path = os.path.join(custom_save_dir, \"eval_metrics.csv\")  # From evaluate\n","per_image_csv_path = os.path.join(custom_save_dir, \"metrics_per_image.csv\")  # From save_metrics_csv\n","fig_save_path = os.path.join(custom_save_dir, \"metrics_visualization.png\")\n","\n","# Set style for nicer plots\n","sns.set(style=\"whitegrid\")\n","# ---------------------------\n","\n","# Load data (use eval_metrics if available, fallback to per_image)\n","if os.path.exists(eval_csv_path):\n","    df = pd.read_csv(eval_csv_path)\n","    print(f\"Loaded {len(df)} samples from {eval_csv_path}\")\n","elif os.path.exists(per_image_csv_path):\n","    df = pd.read_csv(per_image_csv_path)\n","    print(f\"Loaded {len(df)} samples from {per_image_csv_path} (fallback)\")\n","else:\n","    raise FileNotFoundError(f\"No metrics CSV found in {custom_save_dir}! Run evaluate/save_metrics_csv first.\")\n","\n","# Assume columns: 'Index', 'PSNR', 'SSIM' (adjust if needed, e.g., df['psnr'] = df['PSNR'])\n","if 'PSNR' not in df.columns or 'SSIM' not in df.columns:\n","    # Flexible column names\n","    psnr_col = next((col for col in df.columns if 'PSNR' in col.upper()), None)\n","    ssim_col = next((col for col in df.columns if 'SSIM' in col.upper()), None)\n","    if not psnr_col or not ssim_col:\n","        raise ValueError(\"CSV must have PSNR and SSIM columns!\")\n","    df.rename(columns={psnr_col: 'PSNR', ssim_col: 'SSIM'}, inplace=True)\n","\n","psnr_values = df['PSNR'].values\n","ssim_values = df['SSIM'].values\n","\n","# Compute stats\n","print(\"\\nðŸ“Š Metrics Summary:\")\n","print(f\"PSNR: mean={np.mean(psnr_values):.4f}, std={np.std(psnr_values):.4f}, min={np.min(psnr_values):.4f}, max={np.max(psnr_values):.4f}\")\n","print(f\"SSIM: mean={np.mean(ssim_values):.4f}, std={np.std(ssim_values):.4f}, min={np.min(ssim_values):.4f}, max={np.max(ssim_values):.4f}\")\n","\n","# Create figure with subplots\n","fig = plt.figure(figsize=(16, 10))\n","\n","# 1. Histogram PSNR\n","ax1 = fig.add_subplot(2, 2, 1)\n","sns.histplot(psnr_values, bins=20, kde=True, color='blue', ax=ax1)\n","ax1.set_title('PSNR Distribution (Histogram + KDE)')\n","ax1.set_xlabel('PSNR (dB)')\n","ax1.set_ylabel('Frequency')\n","\n","# 2. Histogram SSIM\n","ax2 = fig.add_subplot(2, 2, 2)\n","sns.histplot(ssim_values, bins=20, kde=True, color='green', ax=ax2)\n","ax2.set_title('SSIM Distribution (Histogram + KDE)')\n","ax2.set_xlabel('SSIM')\n","ax2.set_ylabel('Frequency')\n","\n","# 3. Scatter PSNR vs SSIM\n","ax3 = fig.add_subplot(2, 2, 3)\n","sns.scatterplot(x=ssim_values, y=psnr_values, alpha=0.6, color='purple', ax=ax3)\n","ax3.set_title('PSNR vs SSIM (Correlation)')\n","ax3.set_xlabel('SSIM')\n","ax3.set_ylabel('PSNR (dB)')\n","# Add correlation coefficient\n","corr = np.corrcoef(ssim_values, psnr_values)[0, 1]\n","ax3.text(0.05, 0.95, f'Corr: {corr:.3f}', transform=ax3.transAxes, fontsize=12, verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat'))\n","\n","# 4. Box plots\n","ax4 = fig.add_subplot(2, 2, 4)\n","metrics_melted = pd.melt(df[['PSNR', 'SSIM']], var_name='Metric', value_name='Value')\n","sns.boxplot(x='Metric', y='Value', data=metrics_melted, palette=['blue', 'green'], ax=ax4)\n","ax4.set_title('PSNR and SSIM Box Plots (Summary)')\n","\n","plt.tight_layout()\n","plt.savefig(fig_save_path, dpi=150, bbox_inches='tight')\n","print(f\"Visualization saved to {fig_save_path}\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"0K7cTkYsnB5D"},"source":["# 3. Training Loss + LR Curve (Over Epochs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o_Z2krqYnBDj"},"outputs":[],"source":["# @title\n","# =========================================================\n","# Viz 3: Training Curves (Loss + Learning Rate)\n","# =========================================================\n","import json\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","custom_save_dir = \"enter you saved custom folder link\"\n","json_path = os.path.join(custom_save_dir, \"training_results.json\")\n","fig_save_path = os.path.join(custom_save_dir, \"training_curves.png\")\n","\n","with open(json_path, 'r') as f:\n","    results = json.load(f)\n","\n","losses = results['train_losses']\n","epochs = len(losses)\n","lr_step = 15  # From your scheduler\n","lrs = [1e-4 * (0.5 ** (e // lr_step)) for e in range(epochs)]  # Reconstruct LR\n","\n","fig, ax1 = plt.subplots(figsize=(10, 6))\n","ax1.plot(range(1, epochs+1), losses, 'b-', label='Loss')\n","ax1.set_xlabel('Epoch')\n","ax1.set_ylabel('Loss', color='b')\n","ax1.tick_params(axis='y', labelcolor='b')\n","ax1.set_title('Training Loss & LR Over Epochs')\n","\n","ax2 = ax1.twinx()\n","ax2.plot(range(1, epochs+1), lrs, 'r--', label='LR')\n","ax2.set_ylabel('Learning Rate', color='r')\n","ax2.tick_params(axis='y', labelcolor='r')\n","\n","plt.savefig(fig_save_path)\n","print(f\"Saved to {fig_save_path}\")\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}